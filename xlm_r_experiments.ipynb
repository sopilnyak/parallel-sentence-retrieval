{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xlm-r_experiments.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11vRWFVueR9V",
        "colab_type": "text"
      },
      "source": [
        "# Подготовка модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihl-YrWuog3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "model_filename = 'XLMR_triple_1.torch'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jk7_ZDcvGrcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    from torch.cuda import FloatTensor, LongTensor\n",
        "    DEVICE = torch.device('cuda')\n",
        "else:\n",
        "    from torch import FloatTensor, LongTensor\n",
        "    DEVICE = torch.device('cpu')\n",
        "\n",
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7FHqrnZKtZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import XLMRobertaModel, XLMRobertaTokenizer, XLMRobertaConfig\n",
        "\n",
        "model_version = 'xlm-roberta-large'\n",
        "\n",
        "config = XLMRobertaConfig.from_pretrained(model_version)\n",
        "config.output_hidden_states = True\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained(model_version, do_lower_case=False)\n",
        "xlm_model = XLMRobertaModel.from_pretrained(model_version, config=config).to(DEVICE)\n",
        "\n",
        "num_unfreezed = 0\n",
        "freezed_params_num = len(list(xlm_model.parameters())) - num_unfreezed\n",
        "for i, param in enumerate(xlm_model.parameters()):\n",
        "    if i >= freezed_params_num:\n",
        "        param.requires_grad = True\n",
        "    else:\n",
        "        param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmVpCH-yepEZ",
        "colab_type": "text"
      },
      "source": [
        "# Общие классы и методы"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4UC4FdW2EZd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "class Batch():\n",
        "    def __init__(self, anchor, positive, negative):\n",
        "        self.anchor = anchor\n",
        "        self.positive = positive\n",
        "        self.negative = negative\n",
        "\n",
        "\n",
        "class BatchIterator():\n",
        "    def __init__(self, data, batch_size=128, shuffle=True):\n",
        "        self._data = data\n",
        "        self._num_samples = len(data)\n",
        "        self._batch_size = batch_size\n",
        "        self._shuffle = shuffle\n",
        "        self._batches_count = int(math.ceil(len(data) / batch_size))\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self._batches_count\n",
        "    \n",
        "    def __iter__(self):\n",
        "        return self._iterate_batches()\n",
        "\n",
        "    def _iterate_batches(self):\n",
        "        indices = np.arange(self._num_samples)\n",
        "        if self._shuffle:\n",
        "            np.random.shuffle(indices)\n",
        "\n",
        "        for start in range(0, self._num_samples, self._batch_size):\n",
        "            end = min(start + self._batch_size, self._num_samples)\n",
        "\n",
        "            batch_indices = indices[start:end]\n",
        "            batch = self._data.iloc[batch_indices]\n",
        "\n",
        "            yield Batch(tokenize(batch['anchor'].values), tokenize(batch['positive'].values), tokenize(batch['negative'].values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JMPHe8xe5rN",
        "colab_type": "text"
      },
      "source": [
        "# Методы для обучения и тестирования бинарных классификаторов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VR9gffm5B_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "from tqdm import tqdm\n",
        "tqdm.get_lock().locks = []\n",
        "\n",
        "def do_epoch(model, criterion, criterion_emb, data_iter, optimizer=None, name=None):\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    is_train = not optimizer is None\n",
        "    name = name or ''\n",
        "    model.train(is_train)\n",
        "    \n",
        "    batches_count = len(data_iter)\n",
        "    \n",
        "    with torch.autograd.set_grad_enabled(is_train):\n",
        "        with tqdm(total=batches_count) as progress_bar:\n",
        "            for i, batch in enumerate(data_iter):\n",
        "                inputs = convert_batch(batch)\n",
        "                logits_anchor, logits_positive, logits_negative = model.forward(inputs)\n",
        "                \n",
        "                loss = criterion_emb(logits_anchor, logits_positive, logits_negative)\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                if optimizer:\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                progress_bar.update()\n",
        "                progress_bar.set_description('{:>5s} Loss = {:.5f}'.format(name, loss.item()))\n",
        "                \n",
        "            progress_bar.set_description('{:>5s} Loss = {:.5f}'.format(\n",
        "                name, epoch_loss / batches_count)\n",
        "            )\n",
        "            progress_bar.refresh()\n",
        "\n",
        "    return epoch_loss / batches_count\n",
        "\n",
        "\n",
        "def fit(model, criterion, criterion_emb, optimizer, train_iter, epochs_count=1, val_iter=None):\n",
        "    best_val_loss = None\n",
        "    for epoch in range(epochs_count):\n",
        "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
        "        train_loss = do_epoch(model, criterion, criterion_emb, train_iter, optimizer, name_prefix + 'Train:')\n",
        "        \n",
        "        if not val_iter is None:\n",
        "            val_loss = do_epoch(model, criterion, criterion_emb, val_iter, None, name_prefix + '  Val:')\n",
        "        \n",
        "        # Сохраняем модель каждую эпоху\n",
        "        torch.save(model.state_dict(), model_filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4myRrVW_V6H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# Returns precision, recall and F-score for given model and batch generator\n",
        "def evaluate_model(model, test_iter):\n",
        "    for i, batch in enumerate(test_iter):\n",
        "        inputs = convert_batch(batch)\n",
        "        logits = model.forward(inputs)\n",
        "        logits = logits.argmax(-1).cpu().detach().numpy()\n",
        "        target = batch.label.cpu().detach().numpy()\n",
        "        precision, recall, f_score, _ = precision_recall_fscore_support(logits, target, average='binary')\n",
        "        return precision * 100, recall * 100, f_score * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MPVGRT7hrzH",
        "colab_type": "text"
      },
      "source": [
        "# Модель: сиамская сеть + triplet loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TefK3X-ZuEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(sents):\n",
        "    with torch.no_grad():\n",
        "        batch_inputs = []\n",
        "        for sent in sents:\n",
        "            inputs = tokenizer.encode(sent, add_special_tokens=True, pad_to_max_length=True, max_length=60)\n",
        "            batch_inputs.append(inputs)\n",
        "        return torch.tensor(batch_inputs).to(DEVICE)\n",
        "\n",
        "\n",
        "def convert_batch(batch, do_tokenize=False):\n",
        "    if do_tokenize:\n",
        "        return tokenize(batch.anchor), tokenize(batch.positive), tokenize(batch.negative)\n",
        "    return batch.anchor, batch.positive, batch.negative"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a73F0WgjeCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "data = pd.read_csv('triplet_en-ru.csv')\n",
        "data = data.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXAqEqbRjaqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data, test_data = train_test_split(data, train_size=0.7)\n",
        "train_iter = BatchIterator(train_data, 128)\n",
        "test_iter = BatchIterator(test_data, 128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzWDf29S-ATl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TripletLoss(nn.Module):\n",
        "\n",
        "    def __init__(self, margin=0.5):\n",
        "        super(TripletLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, anchor, positive, negative, size_average=True):\n",
        "        distance_positive = (anchor - positive).pow(2).sum(1)  # .pow(.5)\n",
        "        distance_negative = (anchor - negative).pow(2).sum(1)  # .pow(.5)\n",
        "        losses = F.relu(distance_positive - distance_negative + self.margin)\n",
        "        return losses.mean() if size_average else losses.sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7mDCHHILDV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mean_pool_embedding(all_layer_outputs, masks):\n",
        "  sent_embeds = []\n",
        "  for embeds in all_layer_outputs:\n",
        "    embeds = (embeds * masks.unsqueeze(2).float()).sum(dim=1) / masks.sum(dim=1).view(-1, 1).float()\n",
        "    sent_embeds.append(embeds)\n",
        "  return sent_embeds\n",
        "\n",
        "\n",
        "def cls_pool_embedding(all_layer_outputs):\n",
        "  sent_embeds = []\n",
        "  for embeds in all_layer_outputs:\n",
        "    embeds = embeds[:, 0, :]\n",
        "    sent_embeds.append(embeds)\n",
        "  return sent_embeds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnZ2zuy__a8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys, os\n",
        "import logging\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, pretrained, emb_dim=1024, lstm_size=128, out_emb_size=1024):\n",
        "        super().__init__()\n",
        "\n",
        "        self.pretrained = pretrained\n",
        "        self.lstm = nn.LSTM(input_size=emb_dim, hidden_size=lstm_size, batch_first=True, bidirectional=True, num_layers=1)\n",
        "        self.linear = nn.Linear(lstm_size * 2, out_emb_size)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward_(self, input_ids):\n",
        "        attn_mask = input_ids != tokenizer.pad_token_id\n",
        "        _, _, all_layer_outputs = self.pretrained(input_ids, attention_mask=attn_mask)\n",
        "        output = mean_pool_embedding(all_layer_outputs, attn_mask)[16]\n",
        "        # Uncomment to enable training\n",
        "        # _, (ht, _) = self.lstm(all_layer_outputs[16])\n",
        "        # output = torch.cat([ht[0, :, :], ht[1, :, :]], dim=1)\n",
        "        # output = self.dropout(output)\n",
        "        # output = self.linear(output)\n",
        "        return output\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        emb_anchor = self.forward_(inputs[0])\n",
        "        emb_positive = self.forward_(inputs[1])\n",
        "        emb_negative = self.forward_(inputs[2])\n",
        "        return emb_anchor, emb_positive, emb_negative"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtbI9N4-C8Cr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "batch = next(iter(train_iter))\n",
        "model = TransformerEncoder(xlm_model).to(DEVICE)\n",
        "inputs = convert_batch(batch)\n",
        "logits = model(inputs)\n",
        "print(logits[0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbtR8e9XDCLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = TransformerEncoder(xlm_model).to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
        "criterion_emb = TripletLoss().to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmkINh-A83d7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Uncomment to enable training\n",
        "# fit(model, criterion, criterion_emb, optimizer, train_iter, epochs_count=30, val_iter=test_iter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HYU8CAGJJb3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Предикт по паре. Возвращает вероятность того, что пара является переводной.\n",
        "\n",
        "def predict(model, source, target):\n",
        "    source, target = tokenize(source), tokenize(target)\n",
        "    logits = model.forward([source, target])\n",
        "    predicted = logits.argmax(-1).cpu().detach().numpy()\n",
        "    return logits, predicted\n",
        "\n",
        "# Предикт по батчу предложений. Возвращает эмбеддинги предложений.\n",
        "\n",
        "def get_emb(model, sents, is_source=True, do_tokenize=True):\n",
        "    if do_tokenize:\n",
        "        inputs = tokenize(sents)\n",
        "    else:\n",
        "        inputs = torch.stack(sents)\n",
        "    source, target, _ = model([inputs, inputs, inputs])\n",
        "    if is_source:\n",
        "        emb = source\n",
        "    else:\n",
        "        emb = target\n",
        "    return emb.cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nyEkwU4h3At",
        "colab_type": "text"
      },
      "source": [
        "# Тестирование на BUCC и TTW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zywu9PT98SbW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def score(gold, predicted):\n",
        "    error_ids = []\n",
        "    gold = set(gold)\n",
        "    predicted = set(predicted)\n",
        "    correct = gold.intersection(predicted)\n",
        "    error_ids += list(gold.difference(predicted))\n",
        "    num_correct = len(correct)\n",
        "    if num_correct > 0:\n",
        "        precision = num_correct / len(predicted)\n",
        "        recall = num_correct / len(gold)\n",
        "        f1_score = 2 * precision * recall / (precision + recall)\n",
        "        return precision, recall, f1_score, error_ids\n",
        "    return 0, 0, 0, error_ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI9EBWSx8UFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BUCC-based\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "lang = 'ru'\n",
        "lang_root = 'bucc2018/{}-en/'.format(lang)\n",
        "\n",
        "gold = pd.read_csv(os.path.join(lang_root, '{}-en.training.gold'.format(lang)), sep='\\t', names=['source', 'target'])\n",
        "gold = {(item.source, item.target) for _, item in gold.iterrows()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f3uvRbm8Xtc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lang = 'ru'\n",
        "\n",
        "lang_root = 'bucc2018/{}-en/'.format(lang)\n",
        "map_file_prefix = 'dict_bucc2018_{}-en'.format(lang)\n",
        "\n",
        "data_source_map = pd.read_csv(os.path.join(lang_root, '{}-en.training.ru'.format(lang)), sep='\\t', names=['id', 'text'])\n",
        "data_target_map = pd.read_csv(os.path.join(lang_root, '{}-en.training.en'.format(lang)), sep='\\t', names=['id', 'text'])\n",
        "\n",
        "# key = sentence id, value = sentence text\n",
        "source_sents = data_source_map.set_index('id')['text'].to_dict()\n",
        "target_sents = data_target_map.set_index('id')['text'].to_dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPdTO6sohVh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Выкинем предложения на англе, которые должны быть русскими\n",
        "\n",
        "en_letters = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
        "cleaned_source_sents = {}\n",
        "for sent_id, sent in tqdm(source_sents.items()):\n",
        "    # Больше половины символов - английские\n",
        "    if sum(map(sent.count, en_letters)) < len(sent) / 2:\n",
        "        cleaned_source_sents[sent_id] = sent\n",
        "source_sents = cleaned_source_sents\n",
        "\n",
        "\n",
        "# Чистим голд от отсутствующих предложений\n",
        "print(len(gold))\n",
        "cleaned_gold = []\n",
        "for source, target in gold:\n",
        "    if source in source_sents and target in target_sents:\n",
        "        cleaned_gold.append((source, target))\n",
        "gold = cleaned_gold\n",
        "print(len(gold))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTx58ur-foYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TTW Test\n",
        "\n",
        "import pickle\n",
        "\n",
        "def load_data(name):\n",
        "    with open('{}.pkl'.format(name), 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "source_sents = load_data('ttw_test_source_sents')\n",
        "target_sents = load_data('ttw_test_target_sents')\n",
        "gold = load_data('ttw_test_gold')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMrYMZM6Fv7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "map_file_prefix = 'ttw'\n",
        "\n",
        "def load_map(name):\n",
        "    with open(os.path.join('{}_{}.pkl'.format(map_file_prefix, name)), 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "source_sents = load_map('source')\n",
        "target_sents = load_map('target')\n",
        "gold = load_map('gold')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9opRUosre3P0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "assert torch.cuda.is_available()\n",
        "\n",
        "from knn_cuda import KNN\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import faiss\n",
        "from collections import defaultdict\n",
        "\n",
        "assert faiss.get_num_gpus() > 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRe2piBp24wE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "def save_data(data, name):\n",
        "    with open('{}.pkl'.format(name), 'wb') as f:\n",
        "        pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "def load_data(name):\n",
        "    with open('{}.pkl'.format(name), 'rb') as f:\n",
        "        return pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnTTqtR9goPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def knn(x, y, k, mem=5*1024*1024*1024):\n",
        "  dim = x.shape[1]\n",
        "  batch_size = mem // (dim*4)\n",
        "  sim = np.zeros((x.shape[0], k), dtype=np.float32)\n",
        "  ind = np.zeros((x.shape[0], k), dtype=np.int64)\n",
        "  for xfrom in range(0, x.shape[0], batch_size):\n",
        "    xto = min(xfrom + batch_size, x.shape[0])\n",
        "    bsims, binds = [], []\n",
        "    for yfrom in range(0, y.shape[0], batch_size):\n",
        "      yto = min(yfrom + batch_size, y.shape[0])\n",
        "      print('{}-{}  ->  {}-{}'.format(xfrom, xto, yfrom, yto))\n",
        "      idx = faiss.IndexFlatIP(dim)\n",
        "      idx = faiss.index_cpu_to_all_gpus(idx)\n",
        "      idx.add(y[yfrom:yto])\n",
        "      bsim, bind = idx.search(x[xfrom:xto], min(k, yto-yfrom))\n",
        "      bsims.append(bsim)\n",
        "      binds.append(bind + yfrom)\n",
        "      del idx\n",
        "    bsims = np.concatenate(bsims, axis=1)\n",
        "    binds = np.concatenate(binds, axis=1)\n",
        "    aux = np.argsort(-bsims, axis=1)\n",
        "    for i in range(xfrom, xto):\n",
        "      for j in range(k):\n",
        "        sim[i, j] = bsims[i-xfrom, aux[i-xfrom, j]]\n",
        "        ind[i, j] = binds[i-xfrom, aux[i-xfrom, j]]\n",
        "  return sim, ind\n",
        "\n",
        "\n",
        "def get_embeddings(model, id2sent, batch_size=512):\n",
        "    model.eval()\n",
        "    sent_list = list(id2sent.values())\n",
        "    ids = list(id2sent.keys())\n",
        "    with torch.no_grad():\n",
        "        vectors = []\n",
        "        for start in tqdm(range(0, len(sent_list), batch_size)):\n",
        "            end = min(start + batch_size, len(sent_list))\n",
        "            batch_list = sent_list[start:end]\n",
        "            vectors.extend(get_emb(model, batch_list))\n",
        "        \n",
        "    assert len(vectors) == len(ids) == len(sent_list)\n",
        "    vectors = np.array(vectors)\n",
        "    faiss.normalize_L2(vectors)\n",
        "    return vectors\n",
        "\n",
        "\n",
        "def score_pair(x, y, fwd_mean, bwd_mean, margin, dist='cosine'):\n",
        "  if dist == 'cosine':\n",
        "    return margin(x.dot(y), (fwd_mean + bwd_mean) / 2)\n",
        "  else:\n",
        "    l2 = ((x - y) ** 2).sum()\n",
        "    sim = 1 / (1 + l2)\n",
        "    return margin(sim, (fwd_mean + bwd_mean) / 2)\n",
        "\n",
        "\n",
        "def score_candidates(x, y, candidate_inds, fwd_mean, bwd_mean, margin, dist='cosine'):\n",
        "  scores = np.zeros(candidate_inds.shape)\n",
        "  for i in range(scores.shape[0]):\n",
        "    for j in range(scores.shape[1]):\n",
        "      k = candidate_inds[i, j]\n",
        "      scores[i, j] = score_pair(x[i], y[k], fwd_mean[i], bwd_mean[k], margin, dist)\n",
        "  return scores\n",
        "\n",
        "\n",
        "def shift_embeddings(x, y):\n",
        "  print(' - shift embeddings')\n",
        "  delta = x.mean(axis=0) - y.mean(axis=0)\n",
        "  x2y = x - delta\n",
        "  y2x = y + delta\n",
        "  return x2y, y2x\n",
        "\n",
        "\n",
        "def get_candidates(model, sources, targets, return_all=False, do_save=False, save_prefix='xlmr_',\n",
        "                   n_candidates=10, batch_size=512, margin='ratio', threshold=0, retrieval='max', use_shift=True, do_load=False):\n",
        "    if do_load and os.path.exists(save_prefix + 'source_vectors.pkl'):\n",
        "        print('Loading source embeddings...')\n",
        "        source_vectors = load_data(save_prefix + 'source_vectors')\n",
        "    else:\n",
        "        print('Computing source embeddings...')\n",
        "        source_vectors = get_embeddings(model, sources)\n",
        "        if do_save:\n",
        "            save_data(source_vectors, save_prefix + 'source_vectors')\n",
        "    print(source_vectors.shape)\n",
        "    assert len(sources) == len(source_vectors)\n",
        "\n",
        "    if do_load and os.path.exists(drive_root, save_prefix + 'target_vectors.pkl'):\n",
        "        print('Loading target embeddings...')\n",
        "        target_vectors = load_data(drive_root, save_prefix + 'target_vectors')\n",
        "    else:\n",
        "        print('Computing target embeddings...')\n",
        "        target_vectors = get_embeddings(model, targets)\n",
        "        if do_save:\n",
        "            save_data(target_vectors, drive_root, save_prefix + 'target_vectors')\n",
        "    print(target_vectors.shape)\n",
        "    assert len(targets) == len(target_vectors)\n",
        "\n",
        "    if use_shift:\n",
        "        x2y, y2x = shift_embeddings(source_vectors, target_vectors)\n",
        "    \n",
        "    print('Computing distances...')\n",
        "    if use_shift:\n",
        "        x2y_sim, x2y_ind = knn(x2y, target_vectors, min(target_vectors.shape[0], n_candidates))\n",
        "        x2y_mean = x2y_sim.mean(axis=1)\n",
        "    else:\n",
        "        x2y_sim, x2y_ind = knn(source_vectors, target_vectors, min(target_vectors.shape[0], n_candidates))\n",
        "        x2y_mean = x2y_sim.mean(axis=1)\n",
        "\n",
        "    print('Computing reverse distances...')\n",
        "    if use_shift:\n",
        "        y2x_sim, y2x_ind = knn(y2x, source_vectors, min(source_vectors.shape[0], n_candidates))\n",
        "        y2x_mean = y2x_sim.mean(axis=1)\n",
        "    else:\n",
        "        y2x_sim, y2x_ind = knn(target_vectors, source_vectors, n_candidates)\n",
        "        y2x_mean = y2x_sim.mean(axis=1)\n",
        "\n",
        "    if margin == 'absolute':\n",
        "        margin = lambda a, b: a\n",
        "    elif margin == 'distance':\n",
        "        margin = lambda a, b: a - b\n",
        "    else:  # margin == 'ratio':\n",
        "        margin = lambda a, b: a / b\n",
        "\n",
        "    print('Scoring candidates...')\n",
        "    if use_shift:\n",
        "        fwd_scores = score_candidates(x2y, target_vectors, x2y_ind, x2y_mean, y2x_mean, margin)\n",
        "        bwd_scores = score_candidates(y2x, source_vectors, y2x_ind, y2x_mean, x2y_mean, margin)\n",
        "    else:\n",
        "        fwd_scores = score_candidates(source_vectors, target_vectors, x2y_ind, x2y_mean, y2x_mean, margin)\n",
        "        bwd_scores = score_candidates(target_vectors, source_vectors, y2x_ind, y2x_mean, x2y_mean, margin)\n",
        "\n",
        "    fwd_best = x2y_ind[np.arange(source_vectors.shape[0]), fwd_scores.argmax(axis=1)]\n",
        "    bwd_best = y2x_ind[np.arange(target_vectors.shape[0]), bwd_scores.argmax(axis=1)]\n",
        "\n",
        "    print('Retrieving results...')\n",
        "    source_keys = list(sources.keys())\n",
        "    target_keys = list(targets.keys())\n",
        "    predicted = []\n",
        "    distances = []\n",
        "    if retrieval == 'intersection':\n",
        "        for i, j in enumerate(fwd_best):\n",
        "            if bwd_best[j] == i:\n",
        "                predicted.append((source_keys[i], target_keys[j]))\n",
        "                distances.append(fwd_scores[i].max())\n",
        "\n",
        "    if retrieval == 'max':\n",
        "        indices = np.stack((np.concatenate((np.arange(source_vectors.shape[0]), bwd_best)),\n",
        "                            np.concatenate((fwd_best, np.arange(target_vectors.shape[0])))), axis=1)\n",
        "        scores = np.concatenate((fwd_scores.max(axis=1), bwd_scores.max(axis=1)))\n",
        "        seen_src, seen_trg = set(), set()\n",
        "        for i in np.argsort(-scores):\n",
        "            src_ind, trg_ind = indices[i]\n",
        "            if not src_ind in seen_src and not trg_ind in seen_trg:\n",
        "                seen_src.add(src_ind)\n",
        "                seen_trg.add(trg_ind)\n",
        "                if scores[i] > threshold:\n",
        "                    predicted.append((source_keys[src_ind], target_keys[trg_ind]))\n",
        "                    distances.append(scores[i])\n",
        "\n",
        "    id2candidates_full = defaultdict(list)\n",
        "    id2distances_full = defaultdict(list)\n",
        "    for i, _ in enumerate(x2y_ind):\n",
        "        for jj, j in enumerate(x2y_ind[i]):\n",
        "            id2candidates_full[source_keys[i]].append(target_keys[j])\n",
        "            id2distances_full[source_keys[i]].append(fwd_scores[i][jj])\n",
        "\n",
        "    if return_all:\n",
        "        return predicted, distances, id2candidates_full, id2distances_full\n",
        "    return predicted, distances"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk0HDjkZe1NX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "predicted, id2dist, id2candidates_full, id2distances_full = get_candidates(model, source_sents, target_sents, save_prefix='ttw_trained_',\n",
        "                                                                           return_all=True, do_save=True, retrieval='intersection', do_load=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Njs5flgU2DY7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "candidate2score = {}\n",
        "for i, pair in enumerate(predicted):\n",
        "    candidate2score[pair] = id2dist[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtSxn7jE164E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bucc_optimize(candidate2score, gold):\n",
        "  items = sorted(candidate2score.items(), key=lambda x: -x[1])\n",
        "  ngold = len(gold)\n",
        "  nextract = ncorrect = 0\n",
        "  threshold = 0\n",
        "  best_f1 = 0\n",
        "  for i in tqdm(range(len(items))):\n",
        "    nextract += 1\n",
        "    if items[i][0] in gold:\n",
        "      ncorrect += 1\n",
        "    if ncorrect > 0:\n",
        "      precision = ncorrect / nextract\n",
        "      recall = ncorrect / ngold\n",
        "      f1 = 2 * precision * recall / (precision + recall)\n",
        "      if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        threshold = (items[i][1] + items[i + 1][1]) / 2\n",
        "  print(best_f1)\n",
        "  return threshold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4TuhKBl2bjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "threshold = bucc_optimize(candidate2score, gold)\n",
        "print(threshold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwkZH0XX3J2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(predicted))\n",
        "predicted = [pair for pair, score in candidate2score.items() if score >= threshold]\n",
        "print(len(predicted))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLF9-t-mhSPf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, (source_id, target_id) in enumerate(predicted[:50]):\n",
        "    print(f'[{source_id}] {source_sents[source_id]}')\n",
        "    print(f'[{target_id}, dist={id2dist[i]:.6f}] {target_sents[target_id]}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ausaSOpqsVaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre, rec, f1, error_ids = score(gold, predicted)\n",
        "print(f'Precision: {pre:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUh_KrDnwZpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f'Accuracy 10: {accuracy_n(id2candidates_full, gold, 10):.2f}')\n",
        "print(f'Accuracy 5: {accuracy_n(id2candidates_full, gold, 5):.2f}')\n",
        "print(f'Accuracy 1: {accuracy_n(id2candidates_full, gold, 1):.2f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5qkmAkSi1iC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Посмотрим на ошибки\n",
        "\n",
        "for err_source, err_target in error_ids[:100]:\n",
        "    print('{}\\nGold: [{}] {}'.format(source_sents[err_source], err_target, target_sents[err_target]))\n",
        "    \n",
        "    for i, target_id in enumerate(id2candidates_full[err_source]):\n",
        "        print('dist={:.6f} [{}] {}'.format(id2distances_full[err_source][i], target_id, target_sents[target_id]))\n",
        "    print('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARhhoPb6xHct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Длина правильных пар и неправильных\n",
        "\n",
        "source_lens_true = []\n",
        "source_lens_false = []\n",
        "target_lens_true = []\n",
        "target_lens_false = []\n",
        "for source, target in tqdm(predicted):\n",
        "    if (source, target) in gold:\n",
        "        source_lens_true.append(len(source_sents[source]))\n",
        "        target_lens_true.append(len(target_sents[target]))\n",
        "    else:\n",
        "        source_lens_false.append(len(source_sents[source]))\n",
        "        target_lens_false.append(len(target_sents[target]))\n",
        "\n",
        "print(f'True ru mean len: {np.mean(source_lens_true):.4f}')\n",
        "print(f'True en mean len: {np.mean(target_lens_true):.4f}')\n",
        "print(f'False ru mean len: {np.mean(source_lens_false):.4f}')\n",
        "print(f'False en mean len: {np.mean(target_lens_false):.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ib9rNI625AQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}