{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_for_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMWfy1yzRB8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "map_file_prefix = 'ttw'\n",
        "\n",
        "def load_map(name):\n",
        "    with open(os.path.join('{}_{}.pkl'.format(map_file_prefix, name)), 'rb') as f:\n",
        "        return pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZF9T3WtRKt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "source_sents = load_map('source')\n",
        "target_sents = load_map('target')\n",
        "gold = load_map('gold')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2bGwtl1wxek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clean too short sents\n",
        "\n",
        "def clean_sents(sents, min_len=30):\n",
        "    new_sents = {}\n",
        "    for sent_id, sent in sents.items():\n",
        "        if len(sent) >= min_len:\n",
        "            new_sents[sent_id] = sent\n",
        "    return new_sents\n",
        "\n",
        "\n",
        "def clean_gold(source_sents, target_sents, gold):\n",
        "    cleaned_gold = []\n",
        "    for source_id, target_id in gold:\n",
        "        if source_id in source_sents and target_id in target_sents:\n",
        "            cleaned_gold.append((source_id, target_id))\n",
        "    return cleaned_gold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn9g8Lpdxjs5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "source_sents = clean_sents(source_sents)\n",
        "target_sents = clean_sents(target_sents)\n",
        "gold = clean_gold(source_sents, target_sents, gold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyYCIUBGTQkG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "df3a1b62-9658-449b-e873-9cf673a0bf53"
      },
      "source": [
        "# Делим на train и test\n",
        "\n",
        "import random\n",
        "\n",
        "print('--- gold ---')\n",
        "random.shuffle(gold)\n",
        "train_ratio = 0.7\n",
        "train_size = int(train_ratio * len(gold))\n",
        "train_gold, test_gold = gold[:train_size], gold[train_size:]\n",
        "print(len(train_gold))\n",
        "print(len(test_gold))\n",
        "\n",
        "source_in_train_gold = set()\n",
        "target_in_train_gold = set()\n",
        "for source, target in train_gold:\n",
        "    source_in_train_gold.add(source)\n",
        "    target_in_train_gold.add(target)\n",
        "\n",
        "source_in_test_gold = set()\n",
        "target_in_test_gold = set()\n",
        "for source, target in test_gold:\n",
        "    source_in_test_gold.add(source)\n",
        "    target_in_test_gold.add(target)\n",
        "\n",
        "def split_train_test(source_sents, source_in_train_gold, source_in_test_gold):\n",
        "    train_source_sents = {}\n",
        "    test_source_sents = {}\n",
        "    for source_id, source_sent in source_sents.items():\n",
        "        # Если есть и там и там, добавляем и в train и test\n",
        "        if source_id in source_in_train_gold:\n",
        "            train_source_sents[source_id] = source_sent\n",
        "        if source_id in source_in_test_gold:\n",
        "            test_source_sents[source_id] = source_sent\n",
        "        # Иначе рандомно распределяем\n",
        "        if source_id not in source_in_train_gold and source_id not in source_in_test_gold:\n",
        "            if random.randint(0, 1) <= train_ratio:\n",
        "                train_source_sents[source_id] = source_sent\n",
        "            else:\n",
        "                test_source_sents[source_id] = source_sent\n",
        "\n",
        "    print(len(source_sents))\n",
        "    print(len(train_source_sents))\n",
        "    print(len(test_source_sents))\n",
        "\n",
        "    return train_source_sents, test_source_sents\n",
        "\n",
        "print('--- source ---')\n",
        "train_source_sents, test_source_sents = split_train_test(source_sents, source_in_train_gold, source_in_test_gold)\n",
        "print('--- target ---')\n",
        "train_target_sents, test_target_sents = split_train_test(target_sents, target_in_train_gold, target_in_test_gold)\n",
        "\n",
        "\n",
        "# Проверим\n",
        "\n",
        "def check_sents(source_sents, target_sents, gold):\n",
        "    for source, target in gold:\n",
        "        assert source in source_sents\n",
        "        assert target in target_sents\n",
        "\n",
        "check_sents(train_source_sents, train_target_sents, train_gold)\n",
        "check_sents(test_source_sents, test_target_sents, test_gold)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- gold ---\n",
            "42646\n",
            "18278\n",
            "--- source ---\n",
            "826906\n",
            "425467\n",
            "402091\n",
            "--- target ---\n",
            "345927\n",
            "185276\n",
            "160789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_Ks9s9JdbDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "def save_data(data, name):\n",
        "    with open('{}.pkl'.format(name), 'wb') as f:\n",
        "        pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "save_data(train_source_sents, 'ttw_train_source_sents')\n",
        "save_data(test_source_sents, 'ttw_test_source_sents')\n",
        "save_data(train_target_sents, 'ttw_train_target_sents')\n",
        "save_data(test_target_sents, 'ttw_test_target_sents')\n",
        "save_data(train_gold, 'ttw_test_gold')\n",
        "save_data(test_gold, 'ttw_test_gold')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--N1KL4q1YUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "min_len = 30\n",
        "count = 0\n",
        "prefix = 'wikimatrix_'\n",
        "total = 200000\n",
        "for _, row in tqdm(data.head(total).iterrows(), total=total):\n",
        "    if len(row['en']) > min_len:\n",
        "        source_id = prefix + 'en_' + str(count)\n",
        "        target_id = prefix + 'ru_' + str(count)\n",
        "        source_sents[source_id] = str(row['en'])\n",
        "        target_sents[target_id] = str(row['ru'])\n",
        "        gold.append((source_id, target_id))\n",
        "        count += 1\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfKxWnDDxwjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(source_sents))\n",
        "print(len(target_sents))\n",
        "print(len(gold))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXkn6ON6R6CZ",
        "colab_type": "text"
      },
      "source": [
        "## LASER candidates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAlo2XtNQu-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "assert torch.cuda.is_available()\n",
        "\n",
        "from knn_cuda import KNN\n",
        "from laser_wrapper.laser import Laser\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWx7K1vSRQ2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_laser_candidates(sources, targets, n_candidates=10, batch_size=1024):\n",
        "    \n",
        "    knn = KNN(k=n_candidates, transpose_mode=True)\n",
        "    laser = Laser('LASER/models/bilstm.93langs.2018-12-26.pt', 'LASER/models/93langs.fcodes', use_gpu=True)\n",
        "\n",
        "    source_list = list(sources.values())\n",
        "    target_list = list(targets.values())\n",
        "    \n",
        "    source_ids = list(sources.keys())\n",
        "    target_ids = list(targets.keys())\n",
        "    \n",
        "    print('Computing source vectors...')\n",
        "    source_vectors = []\n",
        "    source_batches_ids = []\n",
        "    for start in tqdm(range(0, len(source_list), batch_size)):\n",
        "        end = min(start + batch_size, len(source_list))\n",
        "        batch_source_list = source_list[start:end]\n",
        "        source_vectors.append(laser(batch_source_list))\n",
        "        source_batches_ids.append(source_ids[start:end])\n",
        "    \n",
        "    batch_source_vectors = np.concatenate(source_vectors, axis=0)\n",
        "    \n",
        "    print('Computing target vectors...')\n",
        "    target_vectors = []\n",
        "    target_batches_ids = []\n",
        "    for start in tqdm(range(0, len(target_list), batch_size)):\n",
        "        end = min(start + batch_size, len(target_list))\n",
        "        batch_target_list = target_list[start:end]\n",
        "        target_vectors.append(laser(batch_target_list))\n",
        "        target_batches_ids.append(target_ids[start:end])\n",
        "\n",
        "    id2candidates = {}  # dict {target_id: list of source_ids}\n",
        "    id2distances = {}\n",
        "    \n",
        "    print('Computing distances...')\n",
        "    for batch_target_vectors, batch_target_ids in tqdm(zip(target_vectors, target_batches_ids), total=len(target_vectors)):\n",
        "    \n",
        "        dist, knn_ind = knn(torch.from_numpy(batch_source_vectors).cuda(), torch.from_numpy(batch_target_vectors).cuda())\n",
        "\n",
        "        for target_index in range(len(batch_target_ids)):\n",
        "            target_id = batch_target_ids[target_index]\n",
        "            if target_id in id2candidates:\n",
        "                for i, d in enumerate(dist[target_index]):\n",
        "                    d = d.item()\n",
        "                    if d < id2distances[target_id][i]:\n",
        "                        id2candidates[target_id][i] = source_ids[knn_ind[target_index][i]]\n",
        "                        id2distances[target_id][i] = d\n",
        "            else:\n",
        "                id2candidates[target_id] = [source_ids[ind] for ind in knn_ind[target_index]]\n",
        "                id2distances[target_id] = [d.item() for d in dist[target_index]]\n",
        "    \n",
        "    return id2candidates, id2distances"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rILOo2PdRVvf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "candidates, id2dist = get_laser_candidates(test_source_sents, test_target_sents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCRCVqp8n2sa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "candidates_reverse, id2dist_reverse = get_laser_candidates(target_sents, source_sents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv8ORqQWRsaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "def save_data(data, name):\n",
        "    with open('{}.pkl'.format(name), 'wb') as f:\n",
        "        pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "save_data(candidates, 'ttw_candidates')\n",
        "save_data(id2dist, 'ttw_id2dist')\n",
        "save_data(candidates_reverse, 'ttw_candidates_reverse')\n",
        "save_data(id2dist_reverse, 'ttw_id2dist_reverse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPVIZFzkPdqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(name):\n",
        "    with open('{}.pkl'.format(name), 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "candidates = load_data('ttw_candidates')\n",
        "id2dist = load_data('ttw_id2dist')\n",
        "candidates_reverse = load_data('ttw_candidates_reverse')\n",
        "id2dist_reverse = load_data('ttw_id2dist_reverse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwU9rvmUvjIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for target_id, cand_ids in list(candidates.items())[:20]:\n",
        "    print(target_sents[target_id])\n",
        "    for i, cand_id in enumerate(cand_ids):\n",
        "        print('(dist={:.2f}) {}'.format(id2dist[target_id][i], source_sents[cand_id]))\n",
        "    print('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NJO22Zfo9sN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for target_id, cand_ids in list(candidates_reverse.items())[:20]:\n",
        "    print(source_sents[target_id])\n",
        "    for i, cand_id in enumerate(cand_ids):\n",
        "        print('(dist={:.2f}) {}'.format(id2dist_reverse[target_id][i], target_sents[cand_id]))\n",
        "    print('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaFGHfKe7Wl9",
        "colab_type": "text"
      },
      "source": [
        "## Generate training data for classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_RtmSGG7bPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Возвращает выборку, на которой можно обучать классификатор\n",
        "# Представляет собой некое подобие hard negative mining\n",
        "# Сбалансированные выборки были на [0.3, 0.4]\n",
        "def get_train_data(gold, candidates, id2dist, low_threshold=0.4, high_threshold=0.45):\n",
        "    used_sents = set()  # Делаем так, чтобы предложения в выборках вообще не пересекались\n",
        "    \n",
        "    # Положительные примеры - голд\n",
        "    positives = []\n",
        "    for source, target in gold:\n",
        "        if source not in used_sents and target not in used_sents:\n",
        "            used_sents.add(source)\n",
        "            used_sents.add(target)\n",
        "            positives.append((source, target))\n",
        "    \n",
        "    # Отрицательные примеры - наиболее близкие по лазеру (но не слишком), но не из голд\n",
        "    negatives = []\n",
        "    for target, sources in tqdm(candidates.items()):\n",
        "        for i, source in enumerate(sources):\n",
        "            if (source, target) not in gold and \\\n",
        "                source not in used_sents and \\\n",
        "                target not in used_sents and \\\n",
        "                id2dist[target][i] < high_threshold and id2dist[target][i] > low_threshold:\n",
        "                negatives.append((source, target))\n",
        "                used_sents.add(source)\n",
        "                used_sents.add(target)\n",
        "                break\n",
        "    return positives, negatives"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkdujc0D7qlf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "positives, negatives = get_train_data(gold, candidates, id2dist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiMQe4oS7xk2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e33c6af2-a1d6-42ca-ac36-1d4b75cc6054"
      },
      "source": [
        "len(positives), len(negatives)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26392, 40255)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZOQ0oSr7zr6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "outputId": "f13c8ccb-5159-4b61-e110-40576d292496"
      },
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "sent_dataset = []\n",
        "for source, target in positives:\n",
        "    try:\n",
        "        sent_dataset.append((source_sents[source], target_sents[target], 1))\n",
        "    except KeyError:\n",
        "        pass\n",
        "for source, target in negatives:\n",
        "    sent_dataset.append((source_sents[source], target_sents[target], 0))\n",
        "\n",
        "random.shuffle(sent_dataset)\n",
        "data = pd.DataFrame(sent_dataset, columns=['source', 'target', 'label'])\n",
        "data.to_csv('data_ru-en.csv', index=False)\n",
        "data.head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Too long a holiday makes one reluctant to star...</td>\n",
              "      <td>После долгих праздников не хочется выходить на...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>He claimed that he had returned the book to th...</td>\n",
              "      <td>Он сказал мне, что пошёл в библиотеку, а сам б...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>And I asked the question, who was getting that...</td>\n",
              "      <td>Я задал вопрос, кто получил 3,5 миллиарда долл...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>She sent us a telegram, informing that she wou...</td>\n",
              "      <td>И были даже опросы, которые говорили нам, что ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ten years ago the ward office gave us ballpoin...</td>\n",
              "      <td>10 лет назад, на день совершеннолетия в админи...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>And I think this is what we've done with clima...</td>\n",
              "      <td>Тем не менее, нам удалось прийти к соглашению ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Now we're going to have the real radical exper...</td>\n",
              "      <td>А теперь мы проведем действительно радикальный...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>To become an astronomer, you have to study the...</td>\n",
              "      <td>Чтобы быть астрономом, нужно учиться, а чтобы ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>You don't seem to be as careless as Tom seems ...</td>\n",
              "      <td>Вы должны знать, что Том не такой милый и безо...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>You must pull yourself together and face up to...</td>\n",
              "      <td>Люби себя, чихай на всех — и в жизни ждёт тебя...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Tom, an Englishman, spoke impeccable, accent-f...</td>\n",
              "      <td>По-русски он говорил с лёгким, едва заметным а...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>My grandmother had been sick for a week when I...</td>\n",
              "      <td>Моя бабушка была больна уже неделю, когда я на...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>There is also the fact that the amount of ener...</td>\n",
              "      <td>Имеет место также тот факт, что количество эне...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>All of this field of view is about a semester'...</td>\n",
              "      <td>Всё, что вы здесь видите, это целый курс биоло...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>This is one of the best French restaurants in ...</td>\n",
              "      <td>В Бостоне находится одна из лучших детских бол...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>When she walked through the door, my heart beg...</td>\n",
              "      <td>Когда она меня обняла, я почувствовал, как сил...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>It's hard to know that we won't see each other...</td>\n",
              "      <td>Мы расстались, чтобы никогда больше не встрети...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Employees mutually inspire each other towards ...</td>\n",
              "      <td>Сотрудники взаимно вдохновляют друг друга в на...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>They used to hold raves in those dilapidated w...</td>\n",
              "      <td>Они разместили предупреждающий знак на каждую ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>But if you know stuff, you're more likely to h...</td>\n",
              "      <td>Но если вы в этом разбираетесь, то более вероя...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               source  ... label\n",
              "0   Too long a holiday makes one reluctant to star...  ...     1\n",
              "1   He claimed that he had returned the book to th...  ...     0\n",
              "2   And I asked the question, who was getting that...  ...     1\n",
              "3   She sent us a telegram, informing that she wou...  ...     0\n",
              "4   Ten years ago the ward office gave us ballpoin...  ...     0\n",
              "5   And I think this is what we've done with clima...  ...     0\n",
              "6   Now we're going to have the real radical exper...  ...     1\n",
              "7   To become an astronomer, you have to study the...  ...     0\n",
              "8   You don't seem to be as careless as Tom seems ...  ...     0\n",
              "9   You must pull yourself together and face up to...  ...     0\n",
              "10  Tom, an Englishman, spoke impeccable, accent-f...  ...     0\n",
              "11  My grandmother had been sick for a week when I...  ...     1\n",
              "12  There is also the fact that the amount of ener...  ...     1\n",
              "13  All of this field of view is about a semester'...  ...     1\n",
              "14  This is one of the best French restaurants in ...  ...     0\n",
              "15  When she walked through the door, my heart beg...  ...     0\n",
              "16  It's hard to know that we won't see each other...  ...     0\n",
              "17  Employees mutually inspire each other towards ...  ...     1\n",
              "18  They used to hold raves in those dilapidated w...  ...     0\n",
              "19  But if you know stuff, you're more likely to h...  ...     1\n",
              "\n",
              "[20 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PACmzK-ITOV",
        "colab_type": "text"
      },
      "source": [
        "## Данные для triplet loss (hard negative)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6Q816JmIWkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Возвращает выборку, на которой можно обучать триплет сеть\n",
        "# Берет голд пример и ближайший к нему отрицательный пример\n",
        "def get_triplet_train_data(gold, candidates, id2dist, low_threshold=0.35, high_threshold=0.65, max_triplet_count=4):\n",
        "    \n",
        "    triplets_ru2en = []\n",
        "    used_sents = set()\n",
        "    for positive_source, anchor in gold:\n",
        "        triplet_count = 0\n",
        "        assert anchor in candidates\n",
        "        for i, negative_source in enumerate(candidates[anchor]):\n",
        "            if negative_source != positive_source and id2dist[anchor][i] < high_threshold and id2dist[anchor][i] > low_threshold:\n",
        "                if anchor not in used_sents and positive_source not in used_sents and negative_source not in used_sents:\n",
        "                    triplets_ru2en.append((anchor, positive_source, negative_source))\n",
        "                    used_sents.add(anchor)\n",
        "                    used_sents.add(positive_source)\n",
        "                    used_sents.add(negative_source)\n",
        "                    triplet_count += 1\n",
        "                    if triplet_count > max_triplet_count:\n",
        "                        break\n",
        "    \n",
        "    # Наоборот, anchor на англ (source)\n",
        "    triplets_en2ru = []\n",
        "    for anchor, positive_target in gold:\n",
        "        triplet_count = 0\n",
        "        assert anchor in candidates_reverse\n",
        "        for i, negative_target in enumerate(candidates_reverse[anchor]):\n",
        "            if negative_target != positive_target and id2dist_reverse[anchor][i] < high_threshold and id2dist_reverse[anchor][i] > low_threshold:\n",
        "                if anchor not in used_sents and positive_target not in used_sents and negative_target not in used_sents:\n",
        "                    triplets_en2ru.append((anchor, positive_target, negative_target))\n",
        "                    used_sents.add(anchor)\n",
        "                    used_sents.add(positive_target)\n",
        "                    used_sents.add(negative_target)\n",
        "                    triplet_count += 1\n",
        "                    if triplet_count > max_triplet_count:\n",
        "                        break\n",
        "\n",
        "\n",
        "    return list(set(triplets_ru2en)), list(set(triplets_en2ru))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0domLWDLpss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "triplets_ru2en, triplets_en2ru = get_triplet_train_data(gold, candidates, id2dist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghvqLYiMQ868",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a58a0059-7c9b-4a3a-f692-c3af6d5d5820"
      },
      "source": [
        "len(triplets_ru2en), len(triplets_en2ru)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41422, 5174)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPBBdVn8RjZH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f18946ed-d94a-4c45-86ac-d6085e2ce539"
      },
      "source": [
        "for anchor, source, target in triplets_ru2en[:20]:\n",
        "    try:\n",
        "        print(target_sents[anchor])\n",
        "        print(source_sents[source])\n",
        "        print(source_sents[target])\n",
        "        print('\\n')\n",
        "    except KeyError:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ты не думал проверить уровень масла?\n",
            "Have you thought of checking the oil level?\n",
            "Don't forget to check the oil level.\n",
            "\n",
            "\n",
            "Другое объяснение – тяга к подобному, иначе говоря, «рыбак рыбака видит издалека». В данном случае, двух людей привязывает именно схожесть собственных размеров.\n",
            "Another possibility, very obvious, is homophily, or, birds of a feather flock together; here, I form my tie to you because you and I share a similar body size.\n",
            "My way of looking at things is not at all similar to other people; for a long time, people have criticized my point of view.\n",
            "\n",
            "\n",
            "Большой адронный коллайдер — это крупнейший в мире ускоритель заряженных частиц.\n",
            "The Large Hadron Collider is the world's largest particle accelerator.\n",
            "Hydrogen is the most abundant element in the universe.\n",
            "\n",
            "\n",
            "Я не могу выговорить имя этой девчонки!\n",
            "I can't pronounce this girl's name!\n",
            "I don't remember that guy's name.\n",
            "\n",
            "\n",
            "А когда моя история иссякала, я представлял, что Вселенная этого дровосека это один атом в топоре другого дровосека.\n",
            "And then when I would run out of that story, I would imagine that woodcutter's universe is one atom in the ax of another woodcutter.\n",
            "Once it was believed that the earth was the center of the universe.\n",
            "\n",
            "\n",
            "Очки доставляют мне меньше неудобств, чем контактные линзы.\n",
            "Glasses are more convenient for me than contact lenses.\n",
            "The slope of that is less than linear.\n",
            "\n",
            "\n",
            "Как называется этот цветок по-английски?\n",
            "What do you call this flower in English?\n",
            "This flower is called a lily in English.\n",
            "\n",
            "\n",
            "А вот если у вас его диагностируют на ранней стадии, можно начать лечение. И лечение работает, даже у ВИЧ-инфицированных.\n",
            "And if, however, you are detected very early, diagnosed early, treatment can start, and even in HIV-positives, it makes sense.\n",
            "And now you have cochlear implants that go into people's heads and allow the deaf to begin to hear.\n",
            "\n",
            "\n",
            "А ещё я подумал вот что: какая честь для меня, как политика, выступать на конференции TED, особенно в Великобритании, где у политики такая низкая репутация из-за скандальных расходов [членов парламента].\n",
            "The other thing to think of is what an honor it is, as a politician, to give a TED talk, particularly here in the U.K., where the reputation of politics, with the expenses scandal, has sunk so low.\n",
            "This, I think, is the most important fact to bear in mind in British politics or American politics, and that is: We have run out of money.\n",
            "\n",
            "\n",
            "Другими словами, у нас есть встроенная система, на протяжении нашей жизни обеспечивающая своего рода непрерывность и целостность.\n",
            "So we have an in-built system within our own lives that ensures some kind of continuity.\n",
            "Any homogeneous cycle has a period and a frequency.\n",
            "\n",
            "\n",
            "Сейчас я не хочу вас запутывать, конкретизируя положения, а скорее сказать, что любое из этих явлений,демократия или ислам, - это технологии.\n",
            "Now, I don't want to leave a misimpression by identifying either of these propositions -- rather, either of these phenomena, democracy or Islam -- as technologies.\n",
            "I'm not talking about airy-fairy stuff about culture or psychology, or behavior.\n",
            "\n",
            "\n",
            "Но давайте вернёмся к инфраструктуре.\n",
            "Let's go back to infrastructure.\n",
            "Well, let's go back to this picture.\n",
            "\n",
            "\n",
            "Убеждение людей что-то делать, будь то принимать соли для регидратации или сажать разные культуры, не является актом информирования. \"Давайте дадим им данные, и когда у них будут данные, они станут поступать правильно.\"\n",
            "Convincing people to do something -- take oral rehydration therapy, intercrop, whatever it might be -- is not an act of information: \"Let's give them the data, and when they have data they'll do the right thing.\"\n",
            "If you give people power without oversight, it's a prescription for abuse. They knew that, and let that happen.\n",
            "\n",
            "\n",
            "Телефон: Я просто хотела узнать, чем ты занят.\n",
            "Phone: I was just wondering what you were up to.\n",
            "I just wanted to see how you were doing.\n",
            "\n",
            "\n",
            "Исполнитель применяет стратегию, которая учитывает состояние окружающей среды и контекст, в котором мы находимся.\n",
            "The Actor implements a policy that takes into account the state of the environment and the context in which we operate.\n",
            "The meaning of a word is determined by the context where it is used.\n",
            "\n",
            "\n",
            "У меня воспалились ткани на плечах, а от соленой воды появились язвы на ягодицах.\n",
            "I suffered from tendinitis on my shoulders and saltwater sores on my bottom.\n",
            "I shrugged my shoulders in bewilderment.\n",
            "\n",
            "\n",
            "Таким образом, всякий раз, когда вы теряете информацию, вы приходите к симметрии, и всякий раз, когда вы добавляете информацию в систему, вы нарушаете симметрию.\n",
            "So, whenever you lost information, you'd move to symmetry; whenever you added information to a system, you would break symmetry.\n",
            "And Bateson invented the concept of symmetry breaking, which is that wherever you lose information in a system, you revert back to symmetry.\n",
            "\n",
            "\n",
            "Может быть, я был не такой умный, но по крайней мере такой же разговорчивый.\n",
            "Maybe I wasn't as smart, but I was at least as talkative.\n",
            "He may be intelligent, but he is not wise.\n",
            "\n",
            "\n",
            "Один скрёб конец палки, а второй приложил ухо к другому ее концу.\n",
            "One was scratching at the end of the stick, another child listened at the other end.\n",
            "They go in one ear and out the other.\n",
            "\n",
            "\n",
            "И влияния к худшему — не к лучшему, к худшему.\n",
            "And for the worse -- not for the better, but for the worse.\n",
            "Hope for the best, prepare for the worst.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dP0u6Z1apOOd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "24179b0e-8998-4d8a-9830-8208260bc8b2"
      },
      "source": [
        "for anchor, source, target in triplets_en2ru[:20]:\n",
        "    try:\n",
        "        print(source_sents[anchor])\n",
        "        print(target_sents[source])\n",
        "        print(target_sents[target])\n",
        "        print('\\n')\n",
        "    except KeyError:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tom and Mary weren't invited to John's party.\n",
            "Тома и Мэри не пригласили на вечеринку к Джону.\n",
            "Том и Мэри не пригласили меня на свою свадьбу.\n",
            "\n",
            "\n",
            "It'll be a free download -- thank you, Craig Mundie -- and it'll be available at the website WorldWideTelescope.org, which is something new.\n",
            "Он будет бесплатен для скачивания. Спасибо Крейг Мунди. И его можно будет скачать на сайте WorldwideTelescope.org, недавно созданном.\n",
            "Джеймс Суровики: Фуф... Оба ролика были размещены на Waveofdestruction.org.\n",
            "\n",
            "\n",
            "I haven't been there since October.\n",
            "Я не был там с октября месяца.\n",
            "Этого не случалось с прошлого сентября.\n",
            "\n",
            "\n",
            "Tom is suffering from a nervous disorder.\n",
            "Том страдает нервным расстройством.\n",
            "Том впал в депрессию от переутомления.\n",
            "\n",
            "\n",
            "But, every moment of human history, from the Stone Age to the Information Age, from Sumer and Babylon to the iPod and celebrity gossip, they've all been carried out -- every book that you've read, every poem, every laugh, every tear -- they've all happened here.\n",
            "Но каждое мгновение истории человечества, начиная с Каменного века и до века информационного, от Шумерской цивилизации и Вавилона до айподов и сплетен о знаменитостях, каждое из них имело место -- каждая книга, которую вы прочли, каждое стихотворение, каждая улыбка, каждая слеза, все это произошло здесь.\n",
            "Империалистическая реакция в США свирепо преследует все передовое, прогрессивное, что есть в науке, философии, литературе, искусстве, ее идеологи и политики усиленно распространяют гнилые, реакционные, человеконенавистнические теории и взгляды, используя для этого любой хлам прошлого.\n",
            "\n",
            "\n",
            "I don't really like this kind of music.\n",
            "Мне не очень нравится такая музыка.\n",
            "Ему нравится музыка этого типа.\n",
            "\n",
            "\n",
            "I remember hearing the story once.\n",
            "Я помню, слышал эту историю как-то раз.\n",
            "Слышал я когда-то похожую историю.\n",
            "\n",
            "\n",
            "Do you think that Tom and Mary are going to get back together?\n",
            "Думаешь, Том и Мэри снова будут вместе?\n",
            "Неужели Том и Мария вернулись?\n",
            "\n",
            "\n",
            "I didn't want Tom to think I was stupid.\n",
            "Я не хотел, чтобы Том подумал, что я глупый.\n",
            "Том не хочет выглядеть глупым.\n",
            "\n",
            "\n",
            "I think Tom would've helped us if he'd been here.\n",
            "Думаю, Том бы нам помог, если бы был здесь.\n",
            "Том помог бы нам, если бы мог.\n",
            "\n",
            "\n",
            "Mary put off her trip to Australia.\n",
            "Мэри отложила путешествие в Австралию.\n",
            "Она отложила свою поездку в Мексику.\n",
            "\n",
            "\n",
            "I don't want to live where I work.\n",
            "Я не хочу жить там, где работаю.\n",
            "Я не хочу, чтобы вы здесь работали.\n",
            "\n",
            "\n",
            "The atmosphere mostly consists of nitrogen and oxygen.\n",
            "Атмосфера главным образом состоит из азота и кислорода.\n",
            "Вода разложилась на кислород и водород.\n",
            "\n",
            "\n",
            "Aren't you going to invite Tom to your party?\n",
            "Ты не пригласишь Тома к себе на вечеринку?\n",
            "Почему ты не идёшь на вечеринку Тома?\n",
            "\n",
            "\n",
            "This place gives me a really bad vibe.\n",
            "Это место оставляет во мне весьма неприятные ощущения.\n",
            "Это действительно поставило меня в трудное положение.\n",
            "\n",
            "\n",
            "The legal system in America is the world's finest.\n",
            "Правовая система Америки лучшая в мире.\n",
            "Америка — богатейшая в мире страна.\n",
            "\n",
            "\n",
            "We should tell children how to protect themselves.\n",
            "Мы должны рассказать детям, как защитить себя самому.\n",
            "Вам нужно научиться защищаться.\n",
            "\n",
            "\n",
            "Cyclones can be very dangerous.\n",
            "Циклоны могут быть очень опасны.\n",
            "Химия может быть очень сложной.\n",
            "\n",
            "\n",
            "Why do you say such horrible things about me?\n",
            "Почему ты говоришь обо мне такие ужасные вещи?\n",
            "Как ты смеешь говорить обо мне такие вещи?\n",
            "\n",
            "\n",
            "The more one works, the more one earns.\n",
            "Чем больше работаешь, тем больше зарабатываешь.\n",
            "Чем больше я зарабатываю, тем больше трачу.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4Wl6hwBN7kd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "outputId": "fd82425d-b671-4238-e534-4b0b5958696d"
      },
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "sent_dataset = []\n",
        "for anchor, source, target in triplets_ru2en:\n",
        "    try:\n",
        "        sent_dataset.append((target_sents[anchor], source_sents[source], source_sents[target]))\n",
        "    except KeyError:\n",
        "        pass\n",
        "for anchor, source, target in triplets_en2ru:\n",
        "    try:\n",
        "        sent_dataset.append((source_sents[anchor], target_sents[source], target_sents[target]))\n",
        "    except KeyError:\n",
        "        pass\n",
        "\n",
        "random.shuffle(sent_dataset)\n",
        "data = pd.DataFrame(sent_dataset, columns=['anchor', 'positive', 'negative'])\n",
        "data = data.dropna()  # бывает\n",
        "data.to_csv('triplet_en-ru_clean.csv', index=False)\n",
        "data.head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>anchor</th>\n",
              "      <th>positive</th>\n",
              "      <th>negative</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Что ты думаешь о стихотворении Тома?</td>\n",
              "      <td>What do you think of Tom's poem?</td>\n",
              "      <td>What did you really think of Tom's singing?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ты думаешь, он всё ещё читает мои сообщения?</td>\n",
              "      <td>Do you think he still reads my messages?</td>\n",
              "      <td>Do you think he still loves my letters?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ГБ: Думаю, в каждой религии, каждой вере - и я...</td>\n",
              "      <td>GB: I think every religion, every faith, and I...</td>\n",
              "      <td>RB: I don't actually think that the stereotype...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Как антрополог, я знаю, что именно ходьба сдел...</td>\n",
              "      <td>You know, as an anthropologist, walking is wha...</td>\n",
              "      <td>Making mistakes is what makes us human.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Вот, например. Этого молодого человека зовут Д...</td>\n",
              "      <td>This, for example, this gentleman is called Jo...</td>\n",
              "      <td>He has a son whose name is John.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Каждый год из миллионов абалон составляются по...</td>\n",
              "      <td>Now, millions of abalone every year make this ...</td>\n",
              "      <td>Across the landscapes of Earth were dotted the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Значит, здравый смысл и добрые намерения вступ...</td>\n",
              "      <td>So my common sense, my good intentions, were i...</td>\n",
              "      <td>(Laughter) So my common sense, my good intenti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>And in fact, let's take that one step further.</td>\n",
              "      <td>На самом деле, давайте сделаем тот самый шаг в...</td>\n",
              "      <td>Давай сделаем в отношениях шаг вперёд.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Вы можете разбить материал, например, на корот...</td>\n",
              "      <td>You can break up the material, for example, in...</td>\n",
              "      <td>So you could have something that climbs along ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Мой близкий друг Дэвид понял, о чем я думаю. О...</td>\n",
              "      <td>And my close friend David, he saw the way I wa...</td>\n",
              "      <td>I went there without knowing him. He was 35. I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Ты уверен, что не хочешь сесть за руль?</td>\n",
              "      <td>Are you sure you don't want to drive?</td>\n",
              "      <td>Are you sure you want to quit?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Бремя всех домашних обязанностей ложится на пл...</td>\n",
              "      <td>The burden of all the household tasks usually ...</td>\n",
              "      <td>It says that the rich are always sitting on th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Те, кто там были, думали, что это чистое золото.</td>\n",
              "      <td>Those who were there thought it was pure gold.</td>\n",
              "      <td>The ancients believed the earth was flat.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Но Джо очень боялся конфликта до тех пор, пока...</td>\n",
              "      <td>But he had been so afraid of conflict, until f...</td>\n",
              "      <td>He stood silent for a moment before speaking.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Но сегодня я хочу поделиться с вами личной ист...</td>\n",
              "      <td>But today I've got a personal story to share w...</td>\n",
              "      <td>I want to share a secret with you.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Это отклик на ужасные жилые автоприцепы и уста...</td>\n",
              "      <td>This is in response to the awful mobile traile...</td>\n",
              "      <td>In particular, textbooks and the kind of educa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Не стесняйся задавать своему учителю вопрос.</td>\n",
              "      <td>Don't hesitate to ask your teacher a question.</td>\n",
              "      <td>If you have any questions, ask your teacher.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Кто-то из вас, наверное, читал о рассмотрении ...</td>\n",
              "      <td>Some of you may have read about the FDA's cons...</td>\n",
              "      <td>Some of you may be guilty of having contribute...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Что действительно происходит, это то, что соци...</td>\n",
              "      <td>So what's actually happening is that social ne...</td>\n",
              "      <td>A torrent of peer-to-peer social networks and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Лёд Антарктиды сверкает таким ослепляющим свет...</td>\n",
              "      <td>The ice of Antarctica glows with a light so da...</td>\n",
              "      <td>The glaring light is hurtful to the eyes.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               anchor  ...                                           negative\n",
              "0                Что ты думаешь о стихотворении Тома?  ...        What did you really think of Tom's singing?\n",
              "1        Ты думаешь, он всё ещё читает мои сообщения?  ...            Do you think he still loves my letters?\n",
              "2   ГБ: Думаю, в каждой религии, каждой вере - и я...  ...  RB: I don't actually think that the stereotype...\n",
              "3   Как антрополог, я знаю, что именно ходьба сдел...  ...            Making mistakes is what makes us human.\n",
              "4   Вот, например. Этого молодого человека зовут Д...  ...                   He has a son whose name is John.\n",
              "5   Каждый год из миллионов абалон составляются по...  ...  Across the landscapes of Earth were dotted the...\n",
              "6   Значит, здравый смысл и добрые намерения вступ...  ...  (Laughter) So my common sense, my good intenti...\n",
              "7      And in fact, let's take that one step further.  ...             Давай сделаем в отношениях шаг вперёд.\n",
              "8   Вы можете разбить материал, например, на корот...  ...  So you could have something that climbs along ...\n",
              "9   Мой близкий друг Дэвид понял, о чем я думаю. О...  ...  I went there without knowing him. He was 35. I...\n",
              "10            Ты уверен, что не хочешь сесть за руль?  ...                     Are you sure you want to quit?\n",
              "11  Бремя всех домашних обязанностей ложится на пл...  ...  It says that the rich are always sitting on th...\n",
              "12   Те, кто там были, думали, что это чистое золото.  ...          The ancients believed the earth was flat.\n",
              "13  Но Джо очень боялся конфликта до тех пор, пока...  ...      He stood silent for a moment before speaking.\n",
              "14  Но сегодня я хочу поделиться с вами личной ист...  ...                 I want to share a secret with you.\n",
              "15  Это отклик на ужасные жилые автоприцепы и уста...  ...  In particular, textbooks and the kind of educa...\n",
              "16       Не стесняйся задавать своему учителю вопрос.  ...       If you have any questions, ask your teacher.\n",
              "17  Кто-то из вас, наверное, читал о рассмотрении ...  ...  Some of you may be guilty of having contribute...\n",
              "18  Что действительно происходит, это то, что соци...  ...  A torrent of peer-to-peer social networks and ...\n",
              "19  Лёд Антарктиды сверкает таким ослепляющим свет...  ...          The glaring light is hurtful to the eyes.\n",
              "\n",
              "[20 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94wTpaWsdrwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}